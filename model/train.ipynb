{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cb43b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dim = 21 | positives: 414 negatives: 1656\n",
      "Best params: {'svc__C': 2, 'svc__gamma': 0.05}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9728    0.9493    0.9609       414\n",
      "           1     0.8158    0.8942    0.8532       104\n",
      "\n",
      "    accuracy                         0.9382       518\n",
      "   macro avg     0.8943    0.9218    0.9070       518\n",
      "weighted avg     0.9413    0.9382    0.9393       518\n",
      "\n",
      "\n",
      "→ ../Assets/StreamingAssets/snap_svm.json  (dim 21  | SV 438)\n"
     ]
    }
   ],
   "source": [
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "from sklearn.impute         import SimpleImputer\n",
    "from sklearn.svm            import SVC\n",
    "from sklearn.pipeline       import Pipeline\n",
    "from sklearn.metrics        import classification_report\n",
    "\n",
    "# ───────── config ────────────────────────────────────────────────────────\n",
    "CSV_DIR   = Path(\"../output/files\")          # << adjust if needed\n",
    "WIN       = 7                               # trailing window (0…-10)\n",
    "SHIFT     = WIN - 1\n",
    "TIPS      = [\"ThumbTip\",\"IndexTip\",\"MiddleTip\",\"RingTip\",\"LittleTip\"]\n",
    "KEEP_NEG  = 4                                # keep at most 4× positives\n",
    "PARAMS    = {\"svc__C\":[1,2], \"svc__gamma\":[0.05,0.1]}  # small grid\n",
    "\n",
    "# ───────── load & merge CSVs ─────────────────────────────────────────────\n",
    "files = sorted(CSV_DIR.glob(\"finger_snap_*.csv\"))\n",
    "if not files:\n",
    "    raise SystemExit(f\"No CSVs in {CSV_DIR}\")\n",
    "\n",
    "df = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "df[\"y\"] = (df[\"Label\"].fillna(\"None\") != \"None\").astype(int)\n",
    "\n",
    "needed = [\"Dist\",\"Speed\",\"PalmDist\"] + [f\"{t}.{a}\" for t in TIPS for a in \"xyz\"]\n",
    "df = df.dropna(subset=needed).reset_index(drop=True)\n",
    "\n",
    "# ───────── rolling statistics (min / mean / max) ─────────────────────────\n",
    "roll = df[[\"Dist\",\"Speed\",\"PalmDist\"]].rolling(WIN, min_periods=WIN)\n",
    "\n",
    "df_feat = pd.DataFrame({\n",
    "    \"dMin\" : roll[\"Dist\"].min(),\n",
    "    \"dMean\": roll[\"Dist\"].mean(),\n",
    "    \"sMax\" : roll[\"Speed\"].max(),\n",
    "    \"sMean\": roll[\"Speed\"].mean(),\n",
    "    \"pMin\" : roll[\"PalmDist\"].min(),\n",
    "    \"pMean\": roll[\"PalmDist\"].mean()\n",
    "})\n",
    "\n",
    "# ───────── ΔXYZ & mean-velocities (vectorised shift) ─────────────────────\n",
    "dt = WIN / 60.0                              # seconds in window\n",
    "for tip in TIPS:\n",
    "    for ax in \"xyz\":\n",
    "        col = f\"{tip}.{ax}\"\n",
    "        # Ensure the column is numeric before subtraction\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        delta = df[col] - df[col].shift(SHIFT)\n",
    "        df_feat[f\"{tip[0]}_{ax}_delta\"] = delta \n",
    "\n",
    "# ───────── final feature DF, drop NaNs (first SHIFT rows) ────────────────\n",
    "df_feat[\"y\"] = df[\"y\"]\n",
    "df_feat = df_feat.dropna().reset_index(drop=True)\n",
    "\n",
    "# ───────── optional negative subsample  (speeds-up training) ─────────────\n",
    "pos = df_feat[df_feat.y == 1]\n",
    "neg = df_feat[df_feat.y == 0]\n",
    "neg_keep = min(len(neg), KEEP_NEG * len(pos))\n",
    "neg = neg.sample(neg_keep, random_state=0) if neg_keep else neg\n",
    "df_feat = pd.concat([pos, neg], ignore_index=True).sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Feature dim =\", df_feat.shape[1]-1,\n",
    "      \"| positives:\", len(pos), \"negatives:\", len(neg))\n",
    "\n",
    "# ───────── split & train SVM ─────────────────────────────────────────────\n",
    "X, y = df_feat.drop(columns=\"y\").values, df_feat[\"y\"].values\n",
    "Xtr, Xts, ytr, yts = train_test_split(X, y, test_size=.25,\n",
    "                                      stratify=y, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"sc\" , StandardScaler()),\n",
    "    (\"svc\", SVC(kernel=\"rbf\",\n",
    "                class_weight={0:1, 1:3},  # adjust for class imbalance\n",
    "                probability=False,\n",
    "                cache_size=2048))\n",
    "])\n",
    "\n",
    "clf = GridSearchCV(pipe, PARAMS, cv=4, n_jobs=-1, verbose=0)\n",
    "clf.fit(Xtr, ytr)\n",
    "\n",
    "print(\"Best params:\", clf.best_params_)\n",
    "print(classification_report(yts, clf.predict(Xts), digits=4))\n",
    "\n",
    "# ───────── extract parts & export flat JSON (unchanged schema) ───────────\n",
    "best   = clf.best_estimator_\n",
    "scaler = best.named_steps[\"sc\"]\n",
    "svm    = best.named_steps[\"svc\"]\n",
    "\n",
    "model = dict(\n",
    "    mean      = scaler.mean_.astype(\"float32\").tolist(),\n",
    "    scale     = scaler.scale_.astype(\"float32\").tolist(),\n",
    "    svFlat    = svm.support_vectors_.astype(\"float32\").ravel().tolist(),\n",
    "    nSV       = int(svm.support_vectors_.shape[0]),\n",
    "    featDim   = int(svm.support_vectors_.shape[1]),\n",
    "    dualCoef  = svm.dual_coef_.astype(\"float32\").ravel().tolist(),\n",
    "    intercept = float(svm.intercept_[0]),\n",
    "    gamma     = float(svm._gamma)\n",
    ")\n",
    "\n",
    "out = Path(\"../Assets/StreamingAssets\"); out.mkdir(parents=True, exist_ok=True)\n",
    "with (out / \"snap_svm.json\").open(\"w\") as fp:\n",
    "    json.dump(model, fp, separators=(\",\",\":\"))\n",
    "print(f\"\\n→ {out/'snap_svm.json'}  (dim {model['featDim']}  | SV {model['nSV']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "221bdbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17334b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad2f73ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13131493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca932aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
